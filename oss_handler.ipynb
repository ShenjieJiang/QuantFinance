{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a3f3d37-4c6a-4d8a-a368-ce4f1c3b464b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from setting.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import oss2\n",
    "from setting import SETTINGS\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "import io\n",
    "from dateutil import parser\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from fastparquet import write\n",
    "from pathlib import  Path\n",
    "\n",
    "AccessKeyId = SETTINGS[\"oss.accesskey\"]\n",
    "AccessKeySecret = SETTINGS[\"oss.secret\"]\n",
    "BucketName = SETTINGS[\"oss.bucketname\"]\n",
    "Endpoint = SETTINGS[\"oss.endpoint\"]\n",
    "\n",
    "\n",
    "class newBytes(io.BytesIO):\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class OssClient(object):\n",
    "    __instance = None\n",
    "    __first_init = False\n",
    "\n",
    "    # 单例模式\n",
    "    def __new__(cls, *args, **kwargs):\n",
    "        if not cls.__instance:\n",
    "            cls.__instance = super().__new__(cls)\n",
    "        return cls.__instance\n",
    "\n",
    "    def __init__(self):\n",
    "        cls = self.__class__\n",
    "        if not cls.__first_init:\n",
    "            self.auth = oss2.Auth(AccessKeyId, AccessKeySecret)\n",
    "            self.bucket = oss2.Bucket(self.auth, Endpoint, BucketName)\n",
    "            cls.__first_init = True\n",
    "\n",
    "\n",
    "    def upload_file_from_fileobj(self, object_name, local_file_path):\n",
    "        \"\"\"\n",
    "            upload_file_from_fileobj方法：上传文件对象到oss存储空间, 该方法可用于我们从上游服务接收了图片参数，然后以二进制形式读文件，上传到oss存储空间指定位置（abc/efg/00），\n",
    "        当然也可以将本地文件上传到oss我们的bucket. 其中fileobj不止可以是文件对象，也可以是本地文件路径。 put_object方法底层仍是RESTful API的调用，可以指定headers，规定Content-Type等内容\n",
    "        \"\"\"\n",
    "        # 判断bucket中文件是否存在，也可以不判断，会上传更新\n",
    "        #exist = self.bucket.object_exists(object_name) #<yourObjectName>\n",
    "        #if exist:\n",
    "        #    return True\n",
    "        with open(local_file_path, 'rb') as fileobj:\n",
    "            result = self.bucket.put_object(object_name, fileobj) #<yourObjectName>\n",
    "        if result.status == 200:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def upload_pickle_data(self,df, target_path, *args, report_date=None):\n",
    "        if isinstance(report_date, datetime.date):\n",
    "            d = report_date.strftime(\"%Y-%m-%d\")\n",
    "        if isinstance(report_date, str):\n",
    "            d = parser.parse(report_date).strftime(\"%Y-%m-%d\")\n",
    "        if args:\n",
    "            d = [arg for arg in args][0]\n",
    "        pickle_buffer = io.BytesIO()\n",
    "        pickle.dump(df, pickle_buffer)\n",
    "        target_file_key = os.path.join(target_path, '{}.pkl'.format(d)).replace(\"\\\\\",\"/\")\n",
    "        result = self.bucket.put_object(target_file_key, pickle_buffer.getvalue())\n",
    "        if result.status == 200:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "    def list_files(self,prefix = None):\n",
    "        res = []\n",
    "        for object_info in oss2.ObjectIterator(self.bucket,prefix):\n",
    "            print(object_info.key)\n",
    "            res.append(object_info.key)\n",
    "        return res\n",
    "\n",
    "    def upload_parquet_data(self,df, target_path, *args, report_date=None):\n",
    "        if isinstance(report_date, datetime.date):\n",
    "            d = report_date.strftime(\"%Y-%m-%d\")\n",
    "        if isinstance(report_date, str):\n",
    "            d = parser.parse(report_date).strftime(\"%Y-%m-%d\")\n",
    "        if args:\n",
    "            d = [arg for arg in args][0]\n",
    "        target_file_key = os.path.join(target_path, '{}.parquet'.format(d)).replace(\"\\\\\",\"/\")\n",
    "        mem_buffer = newBytes()\n",
    "        df.to_parquet('noname', engine='fastparquet', open_with=lambda x, y: mem_buffer)\n",
    "        result = self.bucket.put_object(target_file_key, mem_buffer.getvalue())\n",
    "        #f = Path(os.getcwd())/'tmp.parquet'\n",
    "        #write(f, df)\n",
    "        #with open(f, 'rb') as fileobj:\n",
    "        #    result = self.bucket.put_object(target_file_key, fileobj)\n",
    "        #os.remove(f)\n",
    "        if result.status == 200:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def save_data_to_pickle(self,df, file_dir_path, *args,report_date=None):\n",
    "        if isinstance(report_date, datetime.date):\n",
    "            d = report_date.strftime(\"%Y-%m-%d\")\n",
    "        if isinstance(report_date, str):\n",
    "            d = parser.parse(report_date).strftime(\"%Y-%m-%d\")\n",
    "        if args:\n",
    "            d = [arg for arg in args][0]\n",
    "        target_file_key = os.path.join(file_dir_path, '{}.pkl'.format(d))\n",
    "        with open(target_file_key, 'wb') as f:\n",
    "            pickle.dump(df, f)\n",
    "\n",
    "    def save_data_to_parquet(self,df, file_dir_path, *args,report_date=None):\n",
    "        if isinstance(report_date, datetime.date):\n",
    "            d = report_date.strftime(\"%Y-%m-%d\")\n",
    "        if isinstance(report_date, str):\n",
    "            d = parser.parse(report_date).strftime(\"%Y-%m-%d\")\n",
    "        if args:\n",
    "            d = [arg for arg in args][0]\n",
    "        target_file_key = os.path.join(file_dir_path, f'{d}.parquet')\n",
    "        df.to_parquet(target_file_key)\n",
    "\n",
    "\n",
    "    def read_oss_pickle_file(self,object_name):\n",
    "        \"\"\"\n",
    "            download_file_to_fileobj：下载文件到文件流对象。由于get_object接口返回的是一个stream流，需要执行read()后才能计算出返回Object数据的CRC checksum，因此需要在调用该接口后做CRC校验。\n",
    "        \"\"\"\n",
    "        object_stream = self.bucket.get_object(object_name) #<yourObjectName>\n",
    "        result = object_stream.read()\n",
    "        if object_stream.client_crc != object_stream.server_crc:\n",
    "            print(\"The CRC checksum between client and server is inconsistent!\")\n",
    "            result = None\n",
    "        return pickle.loads(result)\n",
    "\n",
    "    def read_oss_parquet_file(self,object_name):\n",
    "        \"\"\"\n",
    "            download_file_to_fileobj：下载文件到文件流对象。由于get_object接口返回的是一个stream流，需要执行read()后才能计算出返回Object数据的CRC checksum，因此需要在调用该接口后做CRC校验。\n",
    "        \"\"\"\n",
    "        object_stream = self.bucket.get_object(object_name) #<yourObjectName>\n",
    "        result = object_stream.read()\n",
    "        i = io.BytesIO(result)\n",
    "        if object_stream.client_crc != object_stream.server_crc:\n",
    "            print(\"The CRC checksum between client and server is inconsistent!\")\n",
    "            result = None\n",
    "        return pd.read_parquet(i)\n",
    "\n",
    "\n",
    "    def download_file_to_loaclfilepath(self, object_name, local_file_path):\n",
    "        \"\"\"\n",
    "            download_file_to_loaclfilepath：下载文件到本地路径。get_object和get_object_to_file的区别是前者是获取文件流实例，可用于代码处理和远程调用参赛。后者是存储到本地路径，返回的是一个http状态的json结果\n",
    "        \"\"\"\n",
    "        result = self.bucket.get_object_to_file(object_name, local_file_path) # ('<yourObjectName>', '<yourLocalFile>')\n",
    "        if result.status == 200:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def generate_temporary_download_url(self,object_name):\n",
    "        \"\"\"\n",
    "            generate_temporary_download_url: 生成加签的临时URL以供授信用户下载。一般在实际业务中，我们是提供给调用方一个临时下载链接，来让其获取文件数据，而不是直接使用以上暴露AccessKeyId和AccessKeySecret的方法。\n",
    "            因此一般我们会存储某条数据oss的路径（<yourObjectName>）与调用方某个唯一标识的对应关系（如手机号身份证号），在调用方请求时，通过该标识获取其数据的oss文件路径（<yourObjectName>），\n",
    "            然后制定过期时间，为其生成临时下载链接\n",
    "            http://bucketname.oss-ap-south-1.aliyuncs.com/abc/efg/0?OSSAccessKeyId=LTA************oN9&Expires=1604638842&Signature=tPgvWz*************Uk%3D\n",
    "        \"\"\"\n",
    "        res_temporary_url = self.bucket.sign_url('GET', object_name, 60, slash_safe=True)\n",
    "        return res_temporary_url\n",
    "\n",
    "\n",
    "oss_client = OssClient()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afabcb1b-24c6-4ea4-8f0f-12fb490ca14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LTAI5tN7V51xtxUmaKxmRsWo rmqsMszRtvurcckVMD9M14riQYshi6 2nd-data oss-cn-shenzhen.aliyuncs.com\n"
     ]
    }
   ],
   "source": [
    "print(AccessKeyId,\n",
    "AccessKeySecret,\n",
    "BucketName,\n",
    "Endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e370d24-6c8b-4614-ba96-ad5847dcc99b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1f712d-3e2d-4965-96fb-3aa66aac0fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
